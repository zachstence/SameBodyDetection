{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune\n",
    "=====\n",
    "***\n",
    "\n",
    "## Importing modules\n",
    "This notebook trains and tests a model and dataset of your choice with various parameters using scikit-learn's `RandomizedSearchCV` and `GridSearchCV` functions to attempt to optimize the hyperparameters of the model. It stores the results into a separate file.\n",
    "\n",
    "The first step is to import the modules needed for calculation and data processing.\n",
    "* `numpy` is necessary for loading the dataset chosen\n",
    "* `sklearn.model_selection.GridSearchCV` and `RandomizedSearchCV` are the functions from scikit-learn that test a classifier with various parameters and returns the set of best parameters.\n",
    "* `time` is used for timing the train and test time for a classifier\n",
    "* `sklearn.metrics.accuracy_score`, `precision_score`, and `f1_score` are used to evalutate how well the optimized classifier performs\n",
    "* `scipy` is used to generate some ranges for the parameters in some classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decide which dataset to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Failed to interpret file './data/created_collected/w4_cw9.npy' as a pickle",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '\n'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-dcd4340d9c78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                 raise IOError(\n\u001b[0;32m--> 431\u001b[0;31m                     \"Failed to interpret file %s as a pickle\" % repr(file))\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mown_fid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Failed to interpret file './data/created_collected/w4_cw9.npy' as a pickle"
     ]
    }
   ],
   "source": [
    "import ipynb.fs.full.TrainTest as TrainTest\n",
    "\n",
    "p = 29\n",
    "a = [2]\n",
    "w = 4\n",
    "cw = 9\n",
    "\n",
    "# path = './data/created_UniMiB-SHAR/nperseg=sqrt/'\n",
    "# file = 'p' + str(p) + '_a' + str(a) + '_w' + str(w) + '_cw' + str(cw)\n",
    "\n",
    "path = './data/created_collected/'\n",
    "file = 'w' + str(w) + '_cw' + str(cw)\n",
    "ext = '.npy'\n",
    "\n",
    "data = np.load(path + file + ext)\n",
    "print(data)\n",
    "\n",
    "print('datapoints: {}'.format(len(data)))\n",
    "true_count = 0\n",
    "for d in data:\n",
    "    if d[1]:\n",
    "        true_count += 1\n",
    "print('num true datapoints: {}'.format(true_count))\n",
    "\n",
    "x_train, y_train, x_test, y_test = TrainTest.get_train_test(data, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for getting the best parameters for a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestParams(clf, param_dict, search='random', n_iter=100, cv=3):\n",
    "    if search == 'random':\n",
    "        clf_search = RandomizedSearchCV(\n",
    "            estimator = clf, \n",
    "            param_distributions = param_dict, \n",
    "            n_iter = n_iter, \n",
    "            cv = cv,\n",
    "            verbose = 1,\n",
    "            n_jobs = -1\n",
    "        )\n",
    "    elif search == 'grid':\n",
    "        clf_search = GridSearchCV(\n",
    "            estimator = clf,\n",
    "            param_grid = param_dict,\n",
    "            cv = cv,\n",
    "            verbose = 1,\n",
    "            n_jobs = -1\n",
    "        )\n",
    "    clf_search.fit(x_train, y_train)\n",
    "    return clf_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to record the results of classifier with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_results(clf, clf_name, trials=10):\n",
    "    print('testing {} through {} trials'.format(clf_name, trials))\n",
    "    avg_acc = 0\n",
    "    avg_prec = 0\n",
    "    avg_f1 = 0\n",
    "    avg_train_time = 0\n",
    "    avg_test_time = 0\n",
    "    \n",
    "    for i in range(trials):\n",
    "        train_start = time.clock()\n",
    "        clf.fit(x_train, y_train)\n",
    "        train_end = time.clock()\n",
    "        \n",
    "        test_start = time.clock()\n",
    "        y_pred = clf.predict(x_test)\n",
    "        test_end = time.clock()\n",
    "        \n",
    "        avg_acc += accuracy_score(y_test, y_pred)\n",
    "        avg_prec += precision_score(y_test, y_pred)\n",
    "        avg_f1 += f1_score(y_test, y_pred)\n",
    "        avg_train_time += (train_end - train_start)\n",
    "        avg_test_time += (test_end - test_start)\n",
    "        print('trial {} / {} finished\\n'.format(i + 1, trials), end='\\r')\n",
    "    \n",
    "    avg_acc /= trials\n",
    "    avg_prec /= trials\n",
    "    avg_f1 /= trials\n",
    "    avg_train_time /= trials\n",
    "    avg_test_time /= trials\n",
    "    \n",
    "    with open('./results/collected/' + clf_name + '/' + file + '.txt', 'a+') as f:\n",
    "        f.write('(best = {})\\n'.format(best))\n",
    "        f.write('trials         : {}\\n'.format(trials))\n",
    "        f.write('avg acc        : {}\\n'.format(avg_acc))\n",
    "        f.write('avg prec       : {}\\n'.format(avg_prec))\n",
    "        f.write('avg f1         : {}\\n'.format(avg_f1))\n",
    "        f.write('avg_train_time : {}\\n'.format(avg_train_time))\n",
    "        f.write('avg_test_time  : {}\\n'.format(avg_test_time))\n",
    "        f.write('-----\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define classifier and parameters to search through, then call functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## NEAREST NEIGHBORS\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf_name = 'knn'\n",
    "clf_options = {\n",
    "    'n_neighbors' : range(1, 6),\n",
    "    'weights' : ['uniform', 'distance'],\n",
    "    'algorithm' : ['auto'],\n",
    "    'leaf_size' : [10, 20, 30, 40, 50],\n",
    "    'p' : [1, 2, 3, 4],\n",
    "    'metric' : ['euclidean', 'manhattan', 'chebyshev', 'minkowski'],\n",
    "#     'metric_params' : [],\n",
    "#     'n_jobs' : []\n",
    "}\n",
    "\n",
    "# ## RANDOM FOREST\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# clf = RandomForestClassifier()\n",
    "# clf_name = 'rf'\n",
    "# clf_options = {\n",
    "#     'n_estimators' : range(100, 2001, 100),\n",
    "#     # 'criterion' : [],\n",
    "#     'max_features' : ['auto', 3, 4, 5],\n",
    "#     'max_depth' : [None, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "#     'min_samples_split' : [2, 5, 10],\n",
    "#     'min_samples_leaf' : [1, 2, 4],\n",
    "#     # 'min_weight_fraction_leaf' : [],\n",
    "#     # 'max_leaf_nodes' : [],\n",
    "#     # 'min_impurity_split' : [],\n",
    "#     # 'min_impurity_decrease' : [],\n",
    "#     'bootstrap' : [True, False]\n",
    "#     # 'oob_score' : [],\n",
    "# }\n",
    "\n",
    "\n",
    "# ## SVM\n",
    "# from sklearn.svm import SVC\n",
    "# clf = SVC()\n",
    "# clf_name = 'svm'\n",
    "# clf_options = {\n",
    "#     'C' : scipy.stats.expon(scale=100),\n",
    "#     'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "#     'degree' : [2, 3, 4, 5],\n",
    "#     'gamma' : scipy.stats.expon(scale=.1),\n",
    "#     'coef0' : [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "#     'probability' : [True, False],\n",
    "#     'shrinking' : [True, False],\n",
    "#     'tol' : [1e-3, 1e-4],\n",
    "# #     'cache_size' : [],\n",
    "#     'class_weight' : [None, 'balanced'],\n",
    "# #     'verbose' : [],\n",
    "# #     'max_iter' : [],\n",
    "# #     'decision_function_shape' : []\n",
    "# #     'random_state' : []\n",
    "# }\n",
    "\n",
    "### DECISION TREE\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# clf = DecisionTreeClassifier()\n",
    "# clf_name = 'dt'\n",
    "# clf_options = {\n",
    "#     'criterion' : ['gini', 'entropy'],\n",
    "#     'splitter' : ['best', 'random'],\n",
    "#     'max_depth' : [None, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "#     'min_samples_split' : [2, 5, 10],\n",
    "#     'min_samples_leaf' : [1, 2, 4],\n",
    "# #     'min_weight_fraction_leaf' : [],\n",
    "#     'max_features' : ['auto', 'log2', 3, 4, 5, None],\n",
    "# #     'random_state' : [],\n",
    "# #     'max_leaf_nodes' : [],\n",
    "# #     'min_impurity_decrease' : [],\n",
    "# #     'min_impurity_split' : [],\n",
    "#     'class_weight' : [None, 'balanced'],\n",
    "#     'presort' : [True, False]\n",
    "# }\n",
    "\n",
    "\n",
    "best = getBestParams(clf, clf_options, search='grid', cv=10)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_clf = KNeighborsClassifier(**best)\n",
    "record_results(best_clf, clf_name, trials=25)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = best_clf.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
