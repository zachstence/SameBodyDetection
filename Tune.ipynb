{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decide which dataset to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datapoints: 51118\n",
      "num true datapoints: 24559\n"
     ]
    }
   ],
   "source": [
    "import ipynb.fs.full.TrainTest as TrainTest\n",
    "\n",
    "# p = 29\n",
    "# a = [2]\n",
    "w = 4\n",
    "cw = 9\n",
    "\n",
    "# path = './data/created_UniMiB-SHAR/nperseg=sqrt/'\n",
    "# file = 'p' + str(p) + '_a' + str(a) + '_w' + str(w) + '_cw' + str(cw)\n",
    "\n",
    "path = './data/created_collected/'\n",
    "file = 'w' + str(w) + '_cw' + str(cw)\n",
    "ext = '.npy'\n",
    "\n",
    "data = np.load(path + file + ext)\n",
    "\n",
    "print('datapoints: {}'.format(len(data)))\n",
    "true_count = 0\n",
    "for d in data:\n",
    "    if d[1]:\n",
    "        true_count += 1\n",
    "print('num true datapoints: {}'.format(true_count))\n",
    "\n",
    "x_train, y_train, x_test, y_test = TrainTest.get_train_test(data, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for getting the best parameters for a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestParams(clf, param_dict, search='random', n_iter=100, cv=3):\n",
    "    if search == 'random':\n",
    "        clf_search = RandomizedSearchCV(\n",
    "            estimator = clf, \n",
    "            param_distributions = param_dict, \n",
    "            n_iter = n_iter, \n",
    "            cv = cv,\n",
    "            verbose = 1,\n",
    "#             n_jobs = -1\n",
    "        )\n",
    "    elif search == 'grid':\n",
    "        clf_search = GridSearchCV(\n",
    "            estimator = clf,\n",
    "            param_grid = param_dict,\n",
    "            cv = cv,\n",
    "            verbose = 1,\n",
    "            n_jobs = -1\n",
    "        )\n",
    "    clf_search.fit(x_train, y_train)\n",
    "    return clf_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to record the results of classifier with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_results(clf, clf_name, trials=10):\n",
    "    avg_acc = 0\n",
    "    avg_prec = 0\n",
    "    avg_f1 = 0\n",
    "    avg_train_time = 0\n",
    "    avg_test_time = 0\n",
    "    \n",
    "    for i in range(trials):\n",
    "        train_start = time.clock()\n",
    "        clf.fit(x_train, y_train)\n",
    "        train_end = time.clock()\n",
    "        \n",
    "        test_start = time.clock()\n",
    "        y_pred = clf.predict(x_test)\n",
    "        test_end = time.clock()\n",
    "        \n",
    "        avg_acc += accuracy_score(y_test, y_pred)\n",
    "        avg_prec += precision_score(y_test, y_pred)\n",
    "        avg_f1 += f1_score(y_test, y_pred)\n",
    "        avg_train_time += (train_end - train_start)\n",
    "        avg_test_time += (test_end - test_start)\n",
    "    \n",
    "    avg_acc /= trials\n",
    "    avg_prec /= trials\n",
    "    avg_f1 /= trials\n",
    "    avg_train_time /= trials\n",
    "    avg_test_time /= trials\n",
    "    \n",
    "    with open('./results/collected/' + clf_name + '/' + file + '.txt', 'a+') as f:\n",
    "        f.write('(best = {})\\n'.format(best))\n",
    "        f.write('trials         : {}\\n'.format(trials))\n",
    "        f.write('avg acc        : {}\\n'.format(avg_acc))\n",
    "        f.write('avg prec       : {}\\n'.format(avg_prec))\n",
    "        f.write('avg f1         : {}\\n'.format(avg_f1))\n",
    "        f.write('avg_train_time : {}\\n'.format(avg_train_time))\n",
    "        f.write('avg_test_time  : {}\\n'.format(avg_test_time))\n",
    "        f.write('-----\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define classifier and parameters to search through, then call functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  8.2min finished\n"
     ]
    }
   ],
   "source": [
    "## NEAREST NEIGHBORS\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf_name = 'knn'\n",
    "clf_options = {\n",
    "    'n_neighbors' : range(1, 6),\n",
    "    'weights' : ['uniform', 'distance'],\n",
    "    'algorithm' : ['auto'],\n",
    "    'leaf_size' : [10, 20, 30, 40, 50],\n",
    "    'p' : [1, 2, 3, 4],\n",
    "    'metric' : ['euclidean', 'manhattan', 'chebyshev', 'minkowski'],\n",
    "#     'metric_params' : [],\n",
    "#     'n_jobs' : []\n",
    "}\n",
    "\n",
    "# ## RANDOM FOREST\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# clf = RandomForestClassifier()\n",
    "# clf_name = 'rf'\n",
    "# clf_options = {\n",
    "#     'n_estimators' : range(100, 2001, 100),\n",
    "#     # 'criterion' : [],\n",
    "#     'max_features' : ['auto', 3, 4, 5],\n",
    "#     'max_depth' : [None, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "#     'min_samples_split' : [2, 5, 10],\n",
    "#     'min_samples_leaf' : [1, 2, 4],\n",
    "#     # 'min_weight_fraction_leaf' : [],\n",
    "#     # 'max_leaf_nodes' : [],\n",
    "#     # 'min_impurity_split' : [],\n",
    "#     # 'min_impurity_decrease' : [],\n",
    "#     'bootstrap' : [True, False]\n",
    "#     # 'oob_score' : [],\n",
    "# }\n",
    "\n",
    "\n",
    "### SVM\n",
    "# from sklearn.svm import SVC\n",
    "# clf = SVC()\n",
    "# clf_name = 'svm'\n",
    "# clf_options = {\n",
    "#     'C' : scipy.stats.expon(scale=100),\n",
    "#     'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "#     'degree' : [2, 3, 4, 5],\n",
    "#     'gamma' : scipy.stats.expon(scale=.1),\n",
    "#     'coef0' : [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "#     'probability' : [True, False],\n",
    "#     'shrinking' : [True, False],\n",
    "#     'tol' : [1e-3, 1e-4],\n",
    "# #     'cache_size' : [],\n",
    "#     'class_weight' : [None, 'balanced'],\n",
    "# #     'verbose' : [],\n",
    "# #     'max_iter' : [],\n",
    "# #     'decision_function_shape' : []\n",
    "# #     'random_state' : []\n",
    "# }\n",
    "\n",
    "### DECISION TREE\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# clf = DecisionTreeClassifier()\n",
    "# clf_name = 'dt'\n",
    "# clf_options = {\n",
    "#     'criterion' : ['gini', 'entropy'],\n",
    "#     'splitter' : ['best', 'random'],\n",
    "#     'max_depth' : [None, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "#     'min_samples_split' : [2, 5, 10],\n",
    "#     'min_samples_leaf' : [1, 2, 4],\n",
    "# #     'min_weight_fraction_leaf' : [],\n",
    "#     'max_features' : ['auto', 'log2', 3, 4, 5, None],\n",
    "# #     'random_state' : [],\n",
    "# #     'max_leaf_nodes' : [],\n",
    "# #     'min_impurity_decrease' : [],\n",
    "# #     'min_impurity_split' : [],\n",
    "#     'class_weight' : [None, 'balanced'],\n",
    "#     'presort' : [True, False]\n",
    "# }\n",
    "\n",
    "\n",
    "best = getBestParams(clf, clf_options, search='random', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "best_clf = KNeighborsClassifier(**best)\n",
    "record_results(best_clf, clf_name)\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
